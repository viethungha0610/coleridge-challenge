{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "\n",
    "import config\n",
    "import dataset\n",
    "import engine\n",
    "from model import EntityModel\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../input/test_ner.json\") as json_file:\n",
    "    test_data = json.load(json_file)\n",
    "    test_paper_ids = list(test_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = joblib.load(\"meta.bin\")\n",
    "enc_tag = meta_data[\"enc_tag\"]\n",
    "num_tag = len(list(enc_tag.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model loading completed!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = EntityModel(num_tag)\n",
    "model.load_state_dict(torch.load(config.MODEL_PATH))\n",
    "model.to(device)\n",
    "print(\"Model loading completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main BERT tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 \t 2100032a-7c33-4bff-97ef-690822c43466\n1 \t 2f392438-e215-4169-bebf-21ac4ff253e1\n2 \t 3f316b38-1a24-45a9-8d8c-4e05a42257c6\n3 \t 8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60\n"
     ]
    }
   ],
   "source": [
    "for index, paper_id in enumerate(test_paper_ids):\n",
    "    print(index, '\\t', paper_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['the', 'three', 'SNPs', 'previously', 'associated', 'with', 'education', 'were', 'variants', 'included', 'on', 'commercially', 'available', 'microarrays', 'and', 'thus', 'were', 'imputed', 'into', 'their', 'datasets', 'Rietveld', 'et', 'al', '2013', 'In', 'the', 'COGENT1', 'studies', 'SNPs', 'were', 'imputed', 'using', 'HapMap3', 'reference', 'panels', 'as', 'previously', 'described', 'Lencz', 'et', 'al', '2013', 'COGENT2', 'samples', 'that', 'did', 'not', 'have', 'genotypes', 'for', 'the', 'SNPs', 'of', 'interest', 'were', 'imputed', 'using', 'IMPUTE2', 'Howie', 'et', 'al', '2009', '.']\n\n[None, 0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 14, 15, 16, 17, 17, 18, 19, 20, 20, 20, 21, 21, 21, 21, 22, 23, 24, 25, 26, 27, 27, 27, 28, 29, 29, 29, 30, 31, 31, 32, 33, 33, 33, 33, 34, 35, 36, 37, 38, 39, 39, 40, 41, 42, 43, 43, 43, 44, 45, 46, 47, 48, 49, 49, 49, 50, 51, 52, 52, 52, 53, 54, 55, 56, 56, 57, 58, 58, 58, 59, 60, 61, 62, 63, None]\n"
     ]
    }
   ],
   "source": [
    "# Testing if aligning text will be possible\n",
    "print(test_data[\"2100032a-7c33-4bff-97ef-690822c43466\"][30])\n",
    "print()\n",
    "print(tokenizer(test_data[\"2100032a-7c33-4bff-97ef-690822c43466\"][30], is_split_into_words=True).word_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 91/91 [00:00<00:00, 705.01it/s]\n",
      "100%|██████████| 713/713 [00:00<00:00, 1019.00it/s]\n",
      "100%|██████████| 263/263 [00:00<00:00, 1417.50it/s]\n",
      "100%|██████████| 186/186 [00:00<00:00, 1282.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Placeholders\n",
    "paper_token_results = {}\n",
    "paper_tokenized_sentences = {}\n",
    "paper_words_ids = {}\n",
    "\n",
    "# Main inference loop\n",
    "for paper_id in tqdm(test_paper_ids):\n",
    "    sentences = test_data[paper_id]\n",
    "    tokenized_sentences = []\n",
    "    tokenized_sentences_word_ids = []\n",
    "    aligned_results = []\n",
    "    for sentence in sentences:\n",
    "        tokenized_output = tokenizer(sentence, is_split_into_words=True)\n",
    "        tokenized_sentences.append(tokenized_output['input_ids'])\n",
    "        tokenized_sentences_word_ids.append(tokenized_output.word_ids())\n",
    "    paper_tokenized_sentences[paper_id] = tokenized_sentences\n",
    "    paper_words_ids[paper_id] = tokenized_sentences_word_ids\n",
    "\n",
    "    # Inference dataset\n",
    "    test_dataset = dataset.EntityDataset(\n",
    "        texts = sentences,\n",
    "        tags = [[0] * len(sentence) for sentence in sentences]\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_dataset\n",
    "        tags = []\n",
    "        results = []\n",
    "        for data in test_dataset:\n",
    "            for k, v in data.items():\n",
    "                data[k] = v.to(device).unsqueeze(0)\n",
    "            tag, _ = model(**data)\n",
    "            tags.append(tag)\n",
    "        for tag, tokenized_sentence in zip(tags, tokenized_sentences):\n",
    "            result = enc_tag.inverse_transform(tag.argmax(2).cpu().numpy().reshape(-1))[:len(tokenized_sentence)]\n",
    "            results.append(result)\n",
    "        paper_token_results[paper_id] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all_tokens = True\n",
    "\n",
    "def tokenize_and_align_labels(tokenized_input, labels, word_ids):\n",
    "    # for i, label in enumerate(labels):\n",
    "    previous_word_idx = None\n",
    "    label_ids = []\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            label_ids.append(labels[word_idx])\n",
    "        else:\n",
    "            label_ids.append(labels[word_idx] if label_all_tokens else -100)\n",
    "        previous_word_idx = word_idx\n",
    "    return label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 78.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Aligning labels loop\n",
    "paper_aligned_labels = {}\n",
    "\n",
    "for paper_id in tqdm(test_paper_ids):\n",
    "    sentences = test_data[paper_id]\n",
    "    paper_aligned_labels[paper_id] = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        aligned_labels = tokenize_and_align_labels(paper_tokenized_sentences[paper_id][i], \n",
    "                                                   paper_token_results[paper_id][i], \n",
    "                                                   paper_words_ids[paper_id][i])\n",
    "        paper_aligned_labels[paper_id].append(aligned_labels)"
   ]
  },
  {
   "source": [
    "### 3 Main output\n",
    "\n",
    "1. <code>paper_token_results</code>: NER tag results with B, I and O tokens\n",
    "\n",
    "2. <code>paper_tokenized_sentences</code>: output for the tokenization process e.g. 101, 102, etc.\n",
    "\n",
    "3. <code>paper_words_ids</code>: word ids for each word in a tokenized sentence\n",
    "\n",
    "4. <code>paper_aligned_labels</code>: containing aligned labels (B, I, O)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Positive predictions\n\nPaper id: 2100032a-7c33-4bff-97ef-690822c43466\nIndex:  84\n\t [-100, 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', -100]\n70\n\t ['[CLS]', 'the', 'laboratory', 'for', 'ne', '##uro', 'imaging', 'at', 'the', 'university', 'of', 'southern', 'california', 'finally', 'several', 'publicly', 'available', 'data', '##set', '##s', 'were', 'included', 'we', 'kindly', 'thank', 'the', 'investigative', 'teams', 'and', 'staff', '##s', 'of', 'the', 'pediatric', 'imaging', 'ne', '##uro', '##co', '##gni', '##tion', 'and', 'genetics', 'ping', 'study', 'the', 'alzheimer', 's', 'disease', 'ne', '##uro', '##ima', '##ging', 'initiative', 'ad', '##ni', 'project', 'and', 'the', 'studies', 'who', 'made', 'their', 'data', 'available', 'in', 'db', '##ga', '##p', '.', '[SEP]']\n70\n['studies', 'who', 'made', 'their', 'data', 'available', 'in', 'db', '##ga', '##p']\n\n\n\nPaper id: 2f392438-e215-4169-bebf-21ac4ff253e1\nIndex:  2\n\t [-100, 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', -100]\n71\n\t ['[CLS]', 'at', 'the', 'organization', 'for', 'economic', 'cooperation', 'and', 'development', 'o', '##ec', '##d', 'the', 'progress', 'in', 'international', 'reading', 'literacy', 'study', 'pi', '##rl', '##s', 'the', 'program', 'for', 'international', 'student', 'assessment', 'pisa', 'and', 'the', 'trends', 'in', 'international', 'mathematics', 'and', 'science', 'study', 'tim', '##ss', 'begun', 'in', '2002', 'the', 'series', 'is', 'published', 'on', 'a', 'biennial', 'basis', 'it', 'should', 'be', 'noted', 'that', 'most', 'of', 'the', 'indicators', 'in', 'this', 'report', 'do', 'not', 'contain', 'data', 'for', 'the', '.', '[SEP]']\n71\n['science', 'study', 'tim', '##ss', 'begun', 'in', '2002', 'the']\n\nIndex:  49\n\t [-100, 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', -100]\n72\n\t ['[CLS]', 'the', 'u', 's', 'education', 'system', 'relative', 'to', 'education', 'systems', 'in', 'other', 'countries', 'these', 'projects', 'include', 'the', 'indicators', 'of', 'national', 'education', 'systems', 'in', '##es', 'at', 'the', 'organization', 'for', 'economic', 'cooperation', 'and', 'development', 'o', '##ec', '##d', 'the', 'progress', 'in', 'international', 'reading', 'literacy', 'study', 'pi', '##rl', '##s', 'the', 'program', 'for', 'international', 'student', 'assessment', 'pisa', 'and', 'the', 'trends', 'in', 'international', 'mathematics', 'and', 'science', 'study', 'tim', '##ss', 'this', 'report', 'comparative', 'indicators', 'of', 'education', 'in', '.', '[SEP]']\n72\n['study', 'tim', '##ss', 'this', 'report', 'comparative', 'indicators', 'of']\n\nIndex:  50\n\t [-100, 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', -100]\n67\n\t ['[CLS]', 'student', 'assessment', 'pisa', 'and', 'the', 'trends', 'in', 'international', 'mathematics', 'and', 'science', 'study', 'tim', '##ss', 'this', 'report', 'comparative', 'indicators', 'of', 'education', 'in', 'the', 'united', 'states', 'and', 'other', 'g', '8', 'countries', '2009', 'draws', 'on', 'the', 'most', 'current', 'information', 'available', 'from', 'most', 'of', 'these', 'projects', 'at', 'the', 'time', 'the', 'report', 'was', 'being', 'produced', 'in', 'the', 'summer', 'and', 'fall', 'of', '2008', 'to', 'present', 'a', 'set', 'of', 'education', 'indicators', '.', '[SEP]']\n67\n['in', 'international', 'mathematics', 'and', 'science', 'study', 'tim', '##ss']\n\nIndex:  175\n\t [-100, 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', -100]\n74\n\t ['[CLS]', 'reading', 'literacy', 'low', 'intermediate', 'high', 'and', 'advanced', 'these', 'bench', '##marks', 'are', 'identical', 'to', 'the', 'cut', '##points', 'used', 'for', 'the', 'trends', 'in', 'international', 'mathematics', 'and', 'science', 'study', 'tim', '##ss', 'information', 'about', 'the', 'rational', '##e', 'underlying', 'the', 'bench', '##marks', 'and', 'the', 'procedures', 'used', 'to', 'set', 'the', 'cut', '##points', 'is', 'available', 'in', 'martin', 'mu', '##llis', 'and', 'kennedy', '2007', 'four', 'points', 'on', 'the', 'scales', 'were', 'identified', 'for', 'use', 'as', 'international', 'bench', '##marks', '400', 'for', 'the', '.', '[SEP]']\n74\n['mathematics', 'and', 'science', 'study', 'tim', '##ss', 'information', 'about']\n\nIndex:  358\n\t [-100, 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', -100]\n67\n\t ['[CLS]', 'about', '39', 'percent', 'of', 'u', 's', 'eighth', 'graders', 'had', 'principals', 'who', 'reported', 'at', 'least', 'a', 'weekly', 'occurrence', 'of', 'intimidation', 'or', 'verbal', 'abuse', 'of', 'other', 'students', 'which', 'is', 'higher', 'than', 'in', 'all', 'other', 'participating', 'g', '8', 'countries', 'using', 'eighth', 'grade', 'data', 'from', 'the', '2007', 'trends', 'in', 'international', 'mathematics', 'and', 'science', 'study', 'tim', '##ss', '2007', 'this', 'indicator', 'presents', 'school', 'principals', 'reports', 'of', 'both', 'the', 'incidence', 'of', '.', '[SEP]']\n67\n['in', 'international', 'mathematics', 'and', 'science', 'study', 'tim', '##ss']\n\nIndex:  359\n\t [-100, 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', -100]\n67\n\t ['[CLS]', 'trends', 'in', 'international', 'mathematics', 'and', 'science', 'study', 'tim', '##ss', '2007', 'this', 'indicator', 'presents', 'school', 'principals', 'reports', 'of', 'both', 'the', 'incidence', 'of', 'behaviors', 'that', 'threaten', 'a', 'safe', 'and', 'orderly', 'environment', 'and', 'their', 'perceptions', 'of', 'these', 'behaviors', 'as', 'a', 'serious', 'problem', 'it', 'should', 'be', 'noted', 'that', 'what', 'constitutes', 'a', 'serious', 'problem', 'may', 'differ', 'from', 'one', 'country', 'to', 'another', 'a', 'relatively', 'low', 'number', 'of', 'threatening', 'behaviors', 'may', '.', '[SEP]']\n67\n['in', 'international', 'mathematics', 'and', 'science', 'study', 'tim', '##ss']\n\nIndex:  438\n\t [-100, 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', -100]\n73\n\t ['[CLS]', 'this', 'indicator', 'presents', 'the', 'percentage', '##s', 'of', 'fourth', 'and', 'eighth', '##grade', '##rs', 'reaching', 'the', 'four', 'international', 'bench', '##marks', 'in', 'science', 'low', 'intermediate', 'high', 'and', 'advanced', 'in', 'the', 'trends', 'in', 'international', 'mathematics', 'and', 'science', 'study', 'tim', '##ss', 'in', '2007', 'on', 'the', 'tim', '##ss', '2007', 'fourth', 'grade', 'science', 'assessment', 'average', 'scale', 'scores', 'ranged', 'from', '500', 'in', 'scotland', 'to', '54', '##8', 'in', 'japan', 'gonzales', 'et', 'al', '2008', 'fourth', 'graders', 'in', 'japan', 'scored', 'higher', '.', '[SEP]']\n73\n['science', 'study', 'tim', '##ss', 'in', '2007', 'on', 'the']\n\nIndex:  456\n\t [-100, 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', -100]\n71\n\t ['[CLS]', 'in', 'science', 'achievement', 'among', 'fourth', 'and', 'eighth', 'grade', 'students', 'in', 'the', 'g', '8', 'countries', 'that', 'participated', 'in', 'the', 'trends', 'in', 'international', 'mathematics', 'and', 'science', 'study', 'tim', '##ss', 'in', '2007', 'on', 'the', 'tim', '##ss', '2007', 'science', 'assessment', 'fourth', 'grade', 'males', 'in', 'germany', 'and', 'italy', 'out', '##per', '##formed', 'females', 'in', 'germany', 'the', 'difference', 'in', 'performance', 'was', '15', 'points', 'with', 'males', 'scoring', 'an', 'average', 'of', '53', '##5', 'compared', 'with', '520', 'among', '.', '[SEP]']\n71\n['in', 'international', 'mathematics', 'and', 'science', 'study', 'tim', '##ss']\n\n\n\nPaper id: 3f316b38-1a24-45a9-8d8c-4e05a42257c6\nIndex:  104\n\t [-100, 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', -100]\n74\n\t ['[CLS]', 'vertical', 'dat', '##um', 'for', 'all', 'data', 'dem', '##s', 'buildings', 'and', 'surge', '##s', 'storm', 'surge', 'modeling', 'data', 'was', 'obtained', 'from', 'the', 'sl', '##osh', 'display', 'program', 'and', 'used', 'to', 'map', 'the', 'extent', 'and', 'depth', 'of', 'in', '##unda', '##tion', 'resulting', 'from', 'various', 'storm', 'scenarios', 'figure', '6', 'the', 'sl', '##osh', 'model', 'was', 'developed', 'by', 'the', 'national', 'weather', 'service', 's', 'nh', '##c', 'to', 'estimate', 'storm', 'surge', 'from', 'hurricanes', 'using', 'storm', 'properties', 'e', 'g', 'track', 'speed', 'and', '.', '[SEP]']\n74\n['weather', 'service', 's']\n\nIndex:  113\n\t [-100, 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'B', -100]\n85\n\t ['[CLS]', 'mapping', 'the', 'storm', 'surge', 'in', '##unda', '##tion', 'involved', 'export', '##ing', 'the', 'data', 'from', 'the', 'sl', '##osh', 'display', 'program', 'that', 'contained', 'the', 'height', 'of', 'the', 'storm', 'surge', 'that', 'was', 'modeled', 'using', 'the', 'mom', '##s', 'approach', 'for', 'the', 'cape', 'hat', '##tera', '##s', 'pam', '##lic', '##o', 'sound', 'h', '##t', '##3', 'basin', 'for', 'each', 'category', 'storm', 'that', 'occurred', 'during', 'high', 'tide', 'figure', '7', 'the', 'sl', '##osh', 'display', 'program', 'exports', 'the', 'data', 'as', 'a', 'shape', '##fi', '##le', 'in', 'w', '##gs', '##8', '##4', 'the', 'shape', '##fi', '##le', 'was', '.', '[SEP]']\n85\n['shape', '##fi', '##le', 'was']\n\n\n\nPaper id: 8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60\nIndex:  66\n\t [-100, 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', -100]\n72\n\t ['[CLS]', 'households', 'at', 'or', 'below', 'this', 'threshold', 'were', 'defined', 'as', 'li', 'whereas', 'those', 'above', 'were', 'nl', '##i', 'this', 'definition', 'follows', 'that', 'used', 'by', 'the', 'er', '##s', 'usd', '##a', 'in', 'their', 'food', 'access', 'research', 'atlas', 'participants', 'county', 'of', 'residence', 'was', 'linked', 'with', 'the', 'usd', '##a', '2013', 'rural', 'urban', 'continuum', 'codes', 'ru', '##cc', '##s', 'united', 'states', 'department', 'of', 'agriculture', '2013', 'to', 'determine', 'if', 'the', 'household', 'was', 'located', 'in', 'an', 'urban', 'or', 'rural', '.', '[SEP]']\n72\n['united', 'states', 'department', 'of']\n\n\n\n"
     ]
    }
   ],
   "source": [
    "# Locating positive predictions\n",
    "print(\"Positive predictions\\n\")\n",
    "for paper_id in test_paper_ids:\n",
    "    print(f\"Paper id: {paper_id}\")\n",
    "    for index, pred in enumerate(paper_token_results[paper_id]):\n",
    "        if 'B' in pred[1:-1]:\n",
    "            print(f'Index: ', index)\n",
    "            print('\\t', paper_aligned_labels[paper_id][index])\n",
    "            print(len(paper_aligned_labels[paper_id][index]))\n",
    "            print('\\t', tokenizer.convert_ids_to_tokens(paper_tokenized_sentences[paper_id][index]))\n",
    "            print(len(tokenizer.convert_ids_to_tokens(paper_tokenized_sentences[paper_id][index])))\n",
    "            \n",
    "            # Getting the positive labels\n",
    "            result = tokenizer.convert_ids_to_tokens(paper_tokenized_sentences[paper_id][index])\n",
    "            positive_token_list = []\n",
    "            for position, token, tag in zip(range(len(result)), tokenizer.convert_ids_to_tokens(paper_tokenized_sentences[paper_id][index]), paper_aligned_labels[paper_id][index]):\n",
    "                if tag in ['B', 'I'] and position not in [0, 1, len(result)-1, len(result)-2]:\n",
    "                    positive_token_list.append(token)\n",
    "            print(positive_token_list)\n",
    "            print()\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "source": [
    "**Notes: **\n",
    "\n",
    "It looks like using the word_ids() method as a medium to align words is not that great, let's just use the tokenized sentence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-100, 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', -100, 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', -100, 'O', -100, 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', -100, 'O', 'O', 'O', 'O', 'O', 'O', -100, -100, 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', -100]\n"
     ]
    }
   ],
   "source": [
    "# Trying out the positive sentence from the last paper\n",
    "print(paper_aligned_labels['8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60'][66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking len\n",
    "faulty_results = []\n",
    "for paper_id in test_paper_ids:\n",
    "    tokenized_sentences_len = [len(sentence) for sentence in test_data[paper_id]]\n",
    "    tokens_len = [len(tokens) for tokens in paper_token_results[paper_id]]\n",
    "    for index, i, j in zip(range(len(tokenized_sentences_len)), tokenized_sentences_len, tokens_len):\n",
    "        if 'B' in paper_token_results[paper_id][index][1:-1]:\n",
    "            if i != j:\n",
    "                j -= 2\n",
    "            try:\n",
    "                assert i == j\n",
    "            except AssertionError:\n",
    "                print(paper_id)\n",
    "                print(i, j)\n",
    "                # print(index)\n",
    "                print(test_data[paper_id][index])\n",
    "                print(paper_token_results[paper_id][index])\n",
    "                faulty_results.append(paper_id)\n",
    "# print('Faulty results:')\n",
    "for item in list(set(faulty_results)):\n",
    "    print('\\t', item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking len\n",
    "faulty_results = []\n",
    "for paper_id in test_paper_ids:\n",
    "    tokenized_sentences_len = [len(sentence) for sentence in paper_tokenized_sentences[paper_id]]\n",
    "    tokens_len = [len(tokens) for tokens in paper_token_results[paper_id]]\n",
    "    for index, i, j in zip(range(len(tokenized_sentences_len)), tokenized_sentences_len, tokens_len):\n",
    "        if 'B' in paper_token_results[paper_id][index][1:-1]:\n",
    "            print(f\"Index: {index}\")\n",
    "            if i != j:\n",
    "                j -= 2\n",
    "            try:\n",
    "                assert i == j\n",
    "            except AssertionError:\n",
    "                print(paper_id)\n",
    "                print(i, j)\n",
    "                # print(index)\n",
    "                print(config.TOKENIZER.convert_ids_to_tokens(paper_tokenized_sentences[paper_id][index]))\n",
    "                print(paper_token_results[paper_id][index])\n",
    "                faulty_results.append(paper_id)\n",
    "# print('Faulty results:')\n",
    "for item in list(set(faulty_results)):\n",
    "    print('\\t', item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Paper ID:\t2100032a-7c33-4bff-97ef-690822c43466\n\n['the', 'Laboratory', 'for', 'Neuro', 'Imaging', 'at', 'the', 'University', 'of', 'Southern', 'California', 'Finally', 'several', 'publicly', 'available', 'datasets', 'were', 'included', 'we', 'kindly', 'thank', 'the', 'investigative', 'teams', 'and', 'staffs', 'of', 'the', 'Pediatric', 'Imaging', 'Neurocognition', 'and', 'Genetics', 'PING', 'study', 'the', 'Alzheimer', 's', 'Disease', 'Neuroimaging', 'Initiative', 'ADNI', 'project', 'and', 'the', 'studies', 'who', 'made', 'their', 'data', 'available', 'in', 'dbGaP', '.']\n54\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B' 'I' 'I' 'I' 'I' 'I' 'I' 'I' 'I'\n 'I' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['the', 'studies', 'who', 'made', 'their', 'data', 'available', 'in', 'dbGaP']\n\n\n\nPaper ID:\t2f392438-e215-4169-bebf-21ac4ff253e1\n\n['at', 'the', 'Organization', 'for', 'Economic', 'Cooperation', 'and', 'Development', 'OECD', 'the', 'Progress', 'in', 'International', 'reading', 'Literacy', 'Study', 'PIrLS', 'the', 'Program', 'for', 'International', 'Student', 'Assessment', 'PISA', 'and', 'the', 'Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study', 'TIMSS', 'Begun', 'in', '2002', 'the', 'series', 'is', 'published', 'on', 'a', 'biennial', 'basis', 'It', 'should', 'be', 'noted', 'that', 'most', 'of', 'the', 'indicators', 'in', 'this', 'report', 'do', 'not', 'contain', 'data', 'for', 'the', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B' 'I' 'I' 'I' 'I'\n 'I' 'I' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['and', 'Science', 'Study', 'TIMSS', 'Begun', 'in', '2002']\n\n\n\n['the', 'u', 'S', 'education', 'system', 'relative', 'to', 'education', 'systems', 'in', 'other', 'countries', 'these', 'projects', 'include', 'the', 'Indicators', 'of', 'national', 'Education', 'Systems', 'InES', 'at', 'the', 'organization', 'for', 'Economic', 'cooperation', 'and', 'development', 'oEcd', 'the', 'Progress', 'in', 'International', 'reading', 'Literacy', 'Study', 'PIrLS', 'the', 'Program', 'for', 'International', 'Student', 'Assessment', 'PISA', 'and', 'the', 'trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study', 'tIMSS', 'this', 'report', 'Comparative', 'Indicators', 'of', 'Education', 'in', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'B' 'I' 'I' 'I' 'I' 'I' 'I' 'O' 'O' 'B']\n64\n['Science', 'Study', 'tIMSS', 'this', 'report', 'Comparative', 'Indicators']\n\n\n\n['Student', 'Assessment', 'PISA', 'and', 'the', 'trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study', 'tIMSS', 'this', 'report', 'Comparative', 'Indicators', 'of', 'Education', 'in', 'the', 'United', 'States', 'and', 'Other', 'G', '8', 'Countries', '2009', 'draws', 'on', 'the', 'most', 'current', 'information', 'available', 'from', 'most', 'of', 'these', 'projects', 'at', 'the', 'time', 'the', 'report', 'was', 'being', 'produced', 'in', 'the', 'summer', 'and', 'fall', 'of', '2008', 'to', 'present', 'a', 'set', 'of', 'education', 'indicators', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'B' 'I' 'I' 'I' 'I' 'I' 'I' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study']\n\n\n\n['reading', 'literacy', 'low', 'intermediate', 'high', 'and', 'advanced', 'These', 'benchmarks', 'are', 'identical', 'to', 'the', 'cutpoints', 'used', 'for', 'the', 'Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study', 'TIMSS', 'Information', 'about', 'the', 'rationale', 'underlying', 'the', 'benchmarks', 'and', 'the', 'procedures', 'used', 'to', 'set', 'the', 'cutpoints', 'is', 'available', 'in', 'Martin', 'Mullis', 'and', 'Kennedy', '2007', 'Four', 'points', 'on', 'the', 'scales', 'were', 'identified', 'for', 'use', 'as', 'international', 'benchmarks', '400', 'for', 'the', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'B' 'I' 'I' 'I' 'I' 'I' 'I' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['International', 'Mathematics', 'and', 'Science', 'Study', 'TIMSS', 'Information']\n\n\n\n['about', '39', 'percent', 'of', 'U', 'S', 'eighth', 'graders', 'had', 'principals', 'who', 'reported', 'at', 'least', 'a', 'weekly', 'occurrence', 'of', 'intimidation', 'or', 'verbal', 'abuse', 'of', 'other', 'students', 'which', 'is', 'higher', 'than', 'in', 'all', 'other', 'participating', 'G', '8', 'countries', 'Using', 'eighth', 'grade', 'data', 'from', 'the', '2007', 'Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study', 'TIMSS', '2007', 'this', 'indicator', 'presents', 'school', 'principals', 'reports', 'of', 'both', 'the', 'incidence', 'of', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B' 'I' 'I' 'I' 'I' 'I' 'I' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study']\n\n\n\n['Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study', 'TIMSS', '2007', 'this', 'indicator', 'presents', 'school', 'principals', 'reports', 'of', 'both', 'the', 'incidence', 'of', 'behaviors', 'that', 'threaten', 'a', 'safe', 'and', 'orderly', 'environment', 'and', 'their', 'perceptions', 'of', 'these', 'behaviors', 'as', 'a', 'serious', 'problem', 'It', 'should', 'be', 'noted', 'that', 'what', 'constitutes', 'a', 'serious', 'problem', 'may', 'differ', 'from', 'one', 'country', 'to', 'another', 'A', 'relatively', 'low', 'number', 'of', 'threatening', 'behaviors', 'may', '.']\n64\n['B' 'B' 'I' 'I' 'I' 'I' 'I' 'I' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study']\n\n\n\n['This', 'indicator', 'presents', 'the', 'percentages', 'of', 'fourth', 'and', 'eighthgraders', 'reaching', 'the', 'four', 'international', 'benchmarks', 'in', 'science', 'low', 'intermediate', 'high', 'and', 'advanced', 'in', 'the', 'Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study', 'TIMSS', 'in', '2007', 'On', 'the', 'TIMSS', '2007', 'fourth', 'grade', 'science', 'assessment', 'average', 'scale', 'scores', 'ranged', 'from', '500', 'in', 'Scotland', 'to', '548', 'in', 'Japan', 'Gonzales', 'et', 'al', '2008', 'Fourth', 'graders', 'in', 'Japan', 'scored', 'higher', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B' 'I' 'I' 'I' 'I' 'I' 'I' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['and', 'Science', 'Study', 'TIMSS', 'in', '2007', 'On']\n\n\n\n['in', 'science', 'achievement', 'among', 'fourth', 'and', 'eighth', 'grade', 'students', 'in', 'the', 'G', '8', 'countries', 'that', 'participated', 'in', 'the', 'Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study', 'TIMSS', 'in', '2007', 'On', 'the', 'TIMSS', '2007', 'science', 'assessment', 'fourth', 'grade', 'males', 'in', 'Germany', 'and', 'Italy', 'outperformed', 'females', 'In', 'Germany', 'the', 'difference', 'in', 'performance', 'was', '15', 'points', 'with', 'males', 'scoring', 'an', 'average', 'of', '535', 'compared', 'with', '520', 'among', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'B' 'I' 'I' 'I' 'I' 'I' 'I' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study']\n\n\n\nPaper ID:\t3f316b38-1a24-45a9-8d8c-4e05a42257c6\n\n['vertical', 'datum', 'for', 'all', 'data', 'DEMs', 'buildings', 'and', 'surges', 'Storm', 'surge', 'modeling', 'data', 'was', 'obtained', 'from', 'the', 'SLOSH', 'display', 'program', 'and', 'used', 'to', 'map', 'the', 'extent', 'and', 'depth', 'of', 'inundation', 'resulting', 'from', 'various', 'storm', 'scenarios', 'Figure', '6', 'The', 'SLOSH', 'model', 'was', 'developed', 'by', 'the', 'National', 'Weather', 'Service', 's', 'NHC', 'to', 'estimate', 'storm', 'surge', 'from', 'hurricanes', 'using', 'storm', 'properties', 'e', 'g', 'track', 'speed', 'and', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B' 'B' 'I' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['National', 'Weather', 'Service']\n\n\n\n['Mapping', 'the', 'storm', 'surge', 'inundation', 'involved', 'exporting', 'the', 'data', 'from', 'the', 'SLOSH', 'display', 'program', 'that', 'contained', 'the', 'height', 'of', 'the', 'storm', 'surge', 'that', 'was', 'modeled', 'using', 'the', 'MOMs', 'approach', 'for', 'the', 'Cape', 'Hatteras', 'Pamlico', 'Sound', 'ht3', 'Basin', 'for', 'each', 'category', 'storm', 'that', 'occurred', 'during', 'high', 'tide', 'Figure', '7', 'The', 'SLOSH', 'display', 'program', 'exports', 'the', 'data', 'as', 'a', 'shapefile', 'in', 'WGS84', 'The', 'shapefile', 'was', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B' 'B' 'B']\n64\n['The', 'shapefile']\n\n\n\nPaper ID:\t8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60\n\n['households', 'at', 'or', 'below', 'this', 'threshold', 'were', 'defined', 'as', 'LI', 'whereas', 'those', 'above', 'were', 'NLI', 'This', 'definition', 'follows', 'that', 'used', 'by', 'the', 'ERS', 'USDA', 'in', 'their', 'Food', 'Access', 'Research', 'Atlas', 'Participants', 'county', 'of', 'residence', 'was', 'linked', 'with', 'the', 'USDA', '2013', 'Rural', 'Urban', 'Continuum', 'Codes', 'RUCCs', 'United', 'States', 'Department', 'of', 'Agriculture', '2013', 'to', 'determine', 'if', 'the', 'household', 'was', 'located', 'in', 'an', 'urban', 'or', 'rural', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B' 'I' 'I' 'I' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['RUCCs', 'United', 'States', 'Department']\n\n\n\n"
     ]
    }
   ],
   "source": [
    "preds_dict = {}\n",
    "\n",
    "for paper_id in test_paper_ids:\n",
    "    preds_dict[paper_id] = []\n",
    "    print(f'Paper ID:\\t{paper_id}')\n",
    "    print(\"\")\n",
    "    for index, result in enumerate(paper_token_results[paper_id]):\n",
    "        preds_preds = []\n",
    "        if 'B' in result[1:-1]:\n",
    "            print(test_data[paper_id][index])\n",
    "            print(len(test_data[paper_id][index]))\n",
    "            print(result)\n",
    "            print(len(result))\n",
    "            preds = []\n",
    "            for i, item in enumerate(result[1:-1]):\n",
    "                try:\n",
    "                    if item == 'B' or item == 'I':\n",
    "                        preds.append(test_data[paper_id][index][i])\n",
    "                except IndexError:\n",
    "                    pass\n",
    "            preds = [item for item in preds if item != '.']    \n",
    "            preds_dict[paper_id].append(\" \".join(preds))\n",
    "            print(preds)\n",
    "            print(\"\\n\\n\")\n",
    "            # preds = [item for item in preds if item != '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Paper ID:\t2100032a-7c33-4bff-97ef-690822c43466\n\n['the', 'Laboratory', 'for', 'Neuro', 'Imaging', 'at', 'the', 'University', 'of', 'Southern', 'California', 'Finally', 'several', 'publicly', 'available', 'datasets', 'were', 'included', 'we', 'kindly', 'thank', 'the', 'investigative', 'teams', 'and', 'staffs', 'of', 'the', 'Pediatric', 'Imaging', 'Neurocognition', 'and', 'Genetics', 'PING', 'study', 'the', 'Alzheimer', 's', 'Disease', 'Neuroimaging', 'Initiative', 'ADNI', 'project', 'and', 'the', 'studies', 'who', 'made', 'their', 'data', 'available', 'in', 'dbGaP', '.']\n54\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B' 'I' 'I' 'I' 'I' 'I' 'I' 'I' 'I'\n 'I' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['the', 'studies', 'who', 'made', 'their', 'data', 'available', 'in', 'dbGaP']\n\n\n\nPaper ID:\t2f392438-e215-4169-bebf-21ac4ff253e1\n\n['at', 'the', 'Organization', 'for', 'Economic', 'Cooperation', 'and', 'Development', 'OECD', 'the', 'Progress', 'in', 'International', 'reading', 'Literacy', 'Study', 'PIrLS', 'the', 'Program', 'for', 'International', 'Student', 'Assessment', 'PISA', 'and', 'the', 'Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study', 'TIMSS', 'Begun', 'in', '2002', 'the', 'series', 'is', 'published', 'on', 'a', 'biennial', 'basis', 'It', 'should', 'be', 'noted', 'that', 'most', 'of', 'the', 'indicators', 'in', 'this', 'report', 'do', 'not', 'contain', 'data', 'for', 'the', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B' 'I' 'I' 'I' 'I'\n 'I' 'I' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['and', 'Science', 'Study', 'TIMSS', 'Begun', 'in', '2002']\n\n\n\n['the', 'u', 'S', 'education', 'system', 'relative', 'to', 'education', 'systems', 'in', 'other', 'countries', 'these', 'projects', 'include', 'the', 'Indicators', 'of', 'national', 'Education', 'Systems', 'InES', 'at', 'the', 'organization', 'for', 'Economic', 'cooperation', 'and', 'development', 'oEcd', 'the', 'Progress', 'in', 'International', 'reading', 'Literacy', 'Study', 'PIrLS', 'the', 'Program', 'for', 'International', 'Student', 'Assessment', 'PISA', 'and', 'the', 'trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study', 'tIMSS', 'this', 'report', 'Comparative', 'Indicators', 'of', 'Education', 'in', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'B' 'I' 'I' 'I' 'I' 'I' 'I' 'O' 'O' 'B']\n64\n['Science', 'Study', 'tIMSS', 'this', 'report', 'Comparative', 'Indicators']\n\n\n\n['Student', 'Assessment', 'PISA', 'and', 'the', 'trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study', 'tIMSS', 'this', 'report', 'Comparative', 'Indicators', 'of', 'Education', 'in', 'the', 'United', 'States', 'and', 'Other', 'G', '8', 'Countries', '2009', 'draws', 'on', 'the', 'most', 'current', 'information', 'available', 'from', 'most', 'of', 'these', 'projects', 'at', 'the', 'time', 'the', 'report', 'was', 'being', 'produced', 'in', 'the', 'summer', 'and', 'fall', 'of', '2008', 'to', 'present', 'a', 'set', 'of', 'education', 'indicators', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'B' 'I' 'I' 'I' 'I' 'I' 'I' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study']\n\n\n\n['reading', 'literacy', 'low', 'intermediate', 'high', 'and', 'advanced', 'These', 'benchmarks', 'are', 'identical', 'to', 'the', 'cutpoints', 'used', 'for', 'the', 'Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study', 'TIMSS', 'Information', 'about', 'the', 'rationale', 'underlying', 'the', 'benchmarks', 'and', 'the', 'procedures', 'used', 'to', 'set', 'the', 'cutpoints', 'is', 'available', 'in', 'Martin', 'Mullis', 'and', 'Kennedy', '2007', 'Four', 'points', 'on', 'the', 'scales', 'were', 'identified', 'for', 'use', 'as', 'international', 'benchmarks', '400', 'for', 'the', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'B' 'I' 'I' 'I' 'I' 'I' 'I' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['International', 'Mathematics', 'and', 'Science', 'Study', 'TIMSS', 'Information']\n\n\n\n['about', '39', 'percent', 'of', 'U', 'S', 'eighth', 'graders', 'had', 'principals', 'who', 'reported', 'at', 'least', 'a', 'weekly', 'occurrence', 'of', 'intimidation', 'or', 'verbal', 'abuse', 'of', 'other', 'students', 'which', 'is', 'higher', 'than', 'in', 'all', 'other', 'participating', 'G', '8', 'countries', 'Using', 'eighth', 'grade', 'data', 'from', 'the', '2007', 'Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study', 'TIMSS', '2007', 'this', 'indicator', 'presents', 'school', 'principals', 'reports', 'of', 'both', 'the', 'incidence', 'of', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B' 'I' 'I' 'I' 'I' 'I' 'I' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study']\n\n\n\n['Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study', 'TIMSS', '2007', 'this', 'indicator', 'presents', 'school', 'principals', 'reports', 'of', 'both', 'the', 'incidence', 'of', 'behaviors', 'that', 'threaten', 'a', 'safe', 'and', 'orderly', 'environment', 'and', 'their', 'perceptions', 'of', 'these', 'behaviors', 'as', 'a', 'serious', 'problem', 'It', 'should', 'be', 'noted', 'that', 'what', 'constitutes', 'a', 'serious', 'problem', 'may', 'differ', 'from', 'one', 'country', 'to', 'another', 'A', 'relatively', 'low', 'number', 'of', 'threatening', 'behaviors', 'may', '.']\n64\n['B' 'B' 'I' 'I' 'I' 'I' 'I' 'I' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study']\n\n\n\n['This', 'indicator', 'presents', 'the', 'percentages', 'of', 'fourth', 'and', 'eighthgraders', 'reaching', 'the', 'four', 'international', 'benchmarks', 'in', 'science', 'low', 'intermediate', 'high', 'and', 'advanced', 'in', 'the', 'Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study', 'TIMSS', 'in', '2007', 'On', 'the', 'TIMSS', '2007', 'fourth', 'grade', 'science', 'assessment', 'average', 'scale', 'scores', 'ranged', 'from', '500', 'in', 'Scotland', 'to', '548', 'in', 'Japan', 'Gonzales', 'et', 'al', '2008', 'Fourth', 'graders', 'in', 'Japan', 'scored', 'higher', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B' 'I' 'I' 'I' 'I' 'I' 'I' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['and', 'Science', 'Study', 'TIMSS', 'in', '2007', 'On']\n\n\n\n['in', 'science', 'achievement', 'among', 'fourth', 'and', 'eighth', 'grade', 'students', 'in', 'the', 'G', '8', 'countries', 'that', 'participated', 'in', 'the', 'Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study', 'TIMSS', 'in', '2007', 'On', 'the', 'TIMSS', '2007', 'science', 'assessment', 'fourth', 'grade', 'males', 'in', 'Germany', 'and', 'Italy', 'outperformed', 'females', 'In', 'Germany', 'the', 'difference', 'in', 'performance', 'was', '15', 'points', 'with', 'males', 'scoring', 'an', 'average', 'of', '535', 'compared', 'with', '520', 'among', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'B' 'I' 'I' 'I' 'I' 'I' 'I' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['Trends', 'in', 'International', 'Mathematics', 'and', 'Science', 'Study']\n\n\n\nPaper ID:\t3f316b38-1a24-45a9-8d8c-4e05a42257c6\n\n['vertical', 'datum', 'for', 'all', 'data', 'DEMs', 'buildings', 'and', 'surges', 'Storm', 'surge', 'modeling', 'data', 'was', 'obtained', 'from', 'the', 'SLOSH', 'display', 'program', 'and', 'used', 'to', 'map', 'the', 'extent', 'and', 'depth', 'of', 'inundation', 'resulting', 'from', 'various', 'storm', 'scenarios', 'Figure', '6', 'The', 'SLOSH', 'model', 'was', 'developed', 'by', 'the', 'National', 'Weather', 'Service', 's', 'NHC', 'to', 'estimate', 'storm', 'surge', 'from', 'hurricanes', 'using', 'storm', 'properties', 'e', 'g', 'track', 'speed', 'and', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B' 'B' 'I' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['National', 'Weather', 'Service']\n\n\n\n['Mapping', 'the', 'storm', 'surge', 'inundation', 'involved', 'exporting', 'the', 'data', 'from', 'the', 'SLOSH', 'display', 'program', 'that', 'contained', 'the', 'height', 'of', 'the', 'storm', 'surge', 'that', 'was', 'modeled', 'using', 'the', 'MOMs', 'approach', 'for', 'the', 'Cape', 'Hatteras', 'Pamlico', 'Sound', 'ht3', 'Basin', 'for', 'each', 'category', 'storm', 'that', 'occurred', 'during', 'high', 'tide', 'Figure', '7', 'The', 'SLOSH', 'display', 'program', 'exports', 'the', 'data', 'as', 'a', 'shapefile', 'in', 'WGS84', 'The', 'shapefile', 'was', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B' 'B' 'B']\n64\n['The', 'shapefile']\n\n\n\nPaper ID:\t8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60\n\n['households', 'at', 'or', 'below', 'this', 'threshold', 'were', 'defined', 'as', 'LI', 'whereas', 'those', 'above', 'were', 'NLI', 'This', 'definition', 'follows', 'that', 'used', 'by', 'the', 'ERS', 'USDA', 'in', 'their', 'Food', 'Access', 'Research', 'Atlas', 'Participants', 'county', 'of', 'residence', 'was', 'linked', 'with', 'the', 'USDA', '2013', 'Rural', 'Urban', 'Continuum', 'Codes', 'RUCCs', 'United', 'States', 'Department', 'of', 'Agriculture', '2013', 'to', 'determine', 'if', 'the', 'household', 'was', 'located', 'in', 'an', 'urban', 'or', 'rural', '.']\n64\n['B' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B' 'I' 'I' 'I' 'O' 'O' 'O' 'O' 'O'\n 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B']\n64\n['RUCCs', 'United', 'States', 'Department']\n\n\n\n"
     ]
    }
   ],
   "source": [
    "preds_dict = {}\n",
    "\n",
    "for paper_id in test_paper_ids:\n",
    "    preds_dict[paper_id] = []\n",
    "    print(f'Paper ID:\\t{paper_id}')\n",
    "    print(\"\")\n",
    "    for index, result in enumerate(paper_token_results[paper_id]):\n",
    "        preds_preds = []\n",
    "        if 'B' in result[1:-1]:\n",
    "            print(test_data[paper_id][index])\n",
    "            print(len(test_data[paper_id][index]))\n",
    "            print(result)\n",
    "            print(len(result))\n",
    "            preds = []\n",
    "            for i, item in enumerate(result[1:-1]):\n",
    "                try:\n",
    "                    if item == 'B' or item == 'I':\n",
    "                        preds.append(test_data[paper_id][index][i])\n",
    "                except IndexError:\n",
    "                    pass\n",
    "            preds = [item for item in preds if item != '.']    \n",
    "            preds_dict[paper_id].append(\" \".join(preds))\n",
    "            print(preds)\n",
    "            print(\"\\n\\n\")\n",
    "            preds = [item for item in preds if item != '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dict_str = {\n",
    "    test_paper_ids[0]: \"|\".join(preds_dict[test_paper_ids[0]]).lower(),\n",
    "    test_paper_ids[1]: \"|\".join(preds_dict[test_paper_ids[1]]).lower(),\n",
    "    test_paper_ids[2]: \"|\".join(preds_dict[test_paper_ids[2]]).lower(),\n",
    "    test_paper_ids[3]: \"|\".join(preds_dict[test_paper_ids[3]]).lower()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'2100032a-7c33-4bff-97ef-690822c43466': 'the studies who made their data available in dbgap',\n",
       " '2f392438-e215-4169-bebf-21ac4ff253e1': 'and science study timss begun in 2002|science study timss this report comparative indicators|trends in international mathematics and science study|international mathematics and science study timss information|trends in international mathematics and science study|trends in international mathematics and science study|and science study timss in 2007 on|trends in international mathematics and science study',\n",
       " '3f316b38-1a24-45a9-8d8c-4e05a42257c6': 'national weather service|the shapefile',\n",
       " '8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60': 'ruccs united states department'}"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "preds_dict_str"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd0c9166686b2c0d2ab991062e289e402ccf81a643b08099ad5f52008b409e32cd3",
   "display_name": "Python 3.8.8 64-bit ('mltorch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "c9166686b2c0d2ab991062e289e402ccf81a643b08099ad5f52008b409e32cd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}